{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turkish NLP Pipeline with BERT \n",
    "\n",
    "1. Sentiment Analysis\n",
    "2. NER Model\n",
    "3. Question Answering\n",
    "4. Text Summarization\n",
    "5. Text Categorization\n",
    "\n",
    "These models are fined tuned based on Turkish-Bert model \n",
    "\n",
    "https://github.com/stefan-it/turkish-bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "* python3\n",
    "* pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-Sentiment Analysis\n",
    "* This model can get up to %95 success rate on our dataset \n",
    "* To see the training detail and the model performce, check the link \\\n",
    " https://huggingface.co/savasy/bert-base-turkish-sentiment-cased\n",
    " \n",
    " https://github.com/savasy/TurkishSentimentAnalysis\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline\n",
    "# load model, it takes time since it loads over 500 MB model file\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"savasy/bert-base-turkish-sentiment-cased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"savasy/bert-base-turkish-sentiment-cased\")\n",
    "\n",
    "# create pipeline\n",
    "sa= pipeline(\"sentiment-analysis\", tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example usage\n",
    "* Label_1: positive\n",
    "* Label_0: negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_1', 'score': 0.5605102}]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "p= sa(\"bu telefon modelleri çok kaliteli ve ayrıca ucuz ve  kolay bulunuyor\")\n",
    "print(p)\n",
    "#[{'label': 'LABEL_1', 'score': 0.9871089}]\n",
    "print (p[0]['label']=='LABEL_1')\n",
    "#True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_0', 'score': 0.9989525}]\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "p= sa(\"Film çok kötü ve oyuncular çok sahteydi\")\n",
    "print(p)\n",
    "#[{'label': 'LABEL_0', 'score': 0.9975505}]\n",
    "print (p[0]['label']=='LABEL_1')\n",
    "#False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test your entire dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Suppose your file has lots of lines of comment and label (1 or 0) (tab seperated)\n",
    "\n",
    "```\n",
    " # yourfile.tsv\n",
    " comment1 ... \\t label\n",
    " comment2 ... \\t label\n",
    "\n",
    " comment-n ... \\t  label\n",
    "...\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# your test code\n",
    "\n",
    "```\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline\n",
    "\n",
    "f=\"/path/to/your/file/yourfile.tsv\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"savasy/bert-base-turkish-sentiment-cased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"savasy/bert-base-turkish-sentiment-cased\")\n",
    "\n",
    "sa= pipeline(\"sentiment-analysis\", tokenizer=tokenizer, model=model)\n",
    "\n",
    "i,crr=0,0\n",
    "for line in open(f):\n",
    " lines=line.strip().split(\"\\t\")\n",
    " if len(lines)==2:\n",
    "  i=i+1\n",
    "  if i%100==0:\n",
    "   print(i)\n",
    "  pred= sa(lines[0])\n",
    "  pred=pred[0][\"label\"].split(\"_\")[1]\n",
    "  if pred== lines[1]:\n",
    "   crr=crr+1\n",
    "\n",
    "print(crr, i, crr/i)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to train and fine-tune your own model, please check \n",
    "\n",
    "https://github.com/savasy/TurkishSentimentAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- Name Entity Recognizer (NER)\n",
    "This model can get %95 accuracy, currently it works with PER, LOC, and ORG\n",
    "\n",
    "check huugingface model repo and ner pipeline repo for other detail\n",
    "\n",
    "* https://huggingface.co/savasy/bert-base-turkish-ner-cased\n",
    "* https://github.com/savasy/Turkish-Bert-Based-NERModel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'word': 'Mustafa', 'score': 0.9938516616821289, 'entity': 'B-PER'}\n",
      "{'word': 'Kemal', 'score': 0.9881671071052551, 'entity': 'I-PER'}\n",
      "{'word': 'Atatürk', 'score': 0.9957979321479797, 'entity': 'I-PER'}\n",
      "{'word': 'Samsun', 'score': 0.9059983491897583, 'entity': 'B-LOC'}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"savasy/bert-base-turkish-ner-cased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"savasy/bert-base-turkish-ner-cased\")\n",
    "\n",
    "ner=pipeline('ner', model=model, tokenizer=tokenizer)\n",
    "res=ner(\"Mustafa Kemal Atatürk 19 Mayıs 1919'da Samsun'a ayak bastı.\")\n",
    "for r in res:\n",
    "    print(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'word': 'Sait', 'score': 0.9995592832565308, 'entity': 'B-PER'}\n",
      "{'word': 'Faik', 'score': 0.999716579914093, 'entity': 'I-PER'}\n",
      "{'word': 'Bur', 'score': 0.7886342406272888, 'entity': 'B-LOC'}\n",
      "{'word': '##gaz', 'score': 0.8438957333564758, 'entity': 'I-LOC'}\n"
     ]
    }
   ],
   "source": [
    "res=ner(\"Sait Faik ömrünün sonuna kadar yazları Burgaz adadaki köşklerinde kalmıştır\")\n",
    "\n",
    "for r in res:\n",
    "    print(r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3- Question Answering  (SQuAD) for Turkish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is tranied with TQuAD dataset (which is SQuAD-like data set of Turkish)\n",
    "\n",
    "https://github.com/TQuad/turkish-nlp-qa-dataset\n",
    "\n",
    "> This dataset is the Turkish Question & Answer dataset on Turkish & Islamic Science History within the scope of Teknofest 2018 Artificial Intelligence competition.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, pipeline\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"savasy/bert-base-turkish-squad\")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"savasy/bert-base-turkish-squad\")\n",
    "\n",
    "nlp=pipeline(\"question-answering\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sait=\"ABASIYANIK, Sait Faik. Hikayeci (Adapazarı 23 Kasım 1906-İstanbul 11 Mayıs 1954). \\\n",
    "İlk öğrenimine Adapazarı’nda Rehber-i Terakki Mektebi’nde başladı. İki yıl kadar Adapazarı İdadisi’nde okudu.\\\n",
    "İstanbul Erkek Lisesi’nde devam ettiği orta öğrenimini Bursa Lisesi’nde tamamladı (1928). İstanbul Edebiyat \\\n",
    "Fakültesi’ne iki yıl devam ettikten sonra babasının isteği üzerine iktisat öğrenimi için İsviçre’ye gitti. \\\n",
    "Kısa süre sonra iktisat öğrenimini bırakarak Lozan’dan Grenoble’a geçti. Üç yıl başıboş bir edebiyat öğrenimi \\\n",
    "gördükten sonra babası tarafından geri çağrıldı (1933). Bir müddet Halıcıoğlu Ermeni Yetim Mektebi'nde Türkçe \\\n",
    "gurup dersleri öğretmenliği yaptı. Ticarete atıldıysa da tutunamadı. Bir ay Haber gazetesinde adliye muhabirliği\\\n",
    "yaptı (1942). Babasının ölümü üzerine aileden kalan emlakin geliri ile avare bir hayata başladı. Evlenemedi.\\\n",
    "Yazları Burgaz adasındaki köşklerinde, kışları Şişli’deki apartmanlarında annesi ile beraber geçen bu fazla \\\n",
    "içkili bohem hayatı ömrünün sonuna kadar sürdü.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
      "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 4341.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.9998962879427609, 'start': 752, 'end': 775, 'answer': 'Babasının ölümü üzerine'}\n"
     ]
    }
   ],
   "source": [
    "print(nlp(question=\"Ne zaman avare bir hayata başladı?\", context=sait))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 114.71it/s]\n",
      "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 5302.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.9957320524499025, 'start': 246, 'end': 262, 'answer': 'Bursa Lisesi’nde'}\n"
     ]
    }
   ],
   "source": [
    "print(nlp(question=\"Sait Faik hangi Lisede orta öğrenimini tamamladı?\", context=sait))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 141.12it/s]\n",
      "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 5017.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.005727019187439786, 'start': 75, 'end': 81, 'answer': '1954).'}\n"
     ]
    }
   ],
   "source": [
    "print(nlp(question=\"Sait Faik bir film yönetmeni mi?\", context=sait))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 131.83it/s]\n",
      "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 4514.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.008398412548299483, 'start': 75, 'end': 81, 'answer': '1954).'}\n"
     ]
    }
   ],
   "source": [
    "# Ask your self ! type your question\n",
    "print(nlp(question=\"...?\", context=sait))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: wikipedia\n",
    "ataturk=\"Atatürk  modern, ilerici ve laik bir ulus devleti oluşturmak için politik, ekonomik ve kültürel alanlarda sekülarist ve milliyetçi \\\n",
    " karakterdeki reformlarını başlattı. Yabancılara tanınan ekonomik imtiyazlar kaldırıldı ve onlara ait üretim araçları ve demiryolları millîleştirildi. \\\n",
    " Tevhîd-i Tedrîsât Kanunu ile eğitim Türk hükûmetinin denetimine girdi. Seküler ve bilimsel eğitim esas alındı. Binlerce yeni okul inşa edildi. \\\n",
    " İlköğretim ücretsiz ve zorunlu hale getirildi. Yabancı okullar devlet denetimine alındı. Köylülerin sırtına yüklenen ağır vergiler azaltıldı. \\\n",
    " Erkeklerin serpuş ve kıyafetlerinde değişiklikler yapıldı. Takvim, saat ve ölçülerde değişikliklere gidildi. \\\n",
    " Mecelle kaldırılarak yerine seküler Türk Kanunu Medenisi yürürlüğe konuldu. Kadınların sivil ve politik hakları pek çok Batı ülkesinden önce tanındı. \\\n",
    " Çok eşlilik yasaklandı. Kadınların şahitliği ve miras hakkı erkeklerinkiyle eşit hale getirildi. Benzer şekilde, dünyanın çoğu ülkesinden önce olarak \\\n",
    " Türkiye'de kadınların ilkin yerel seçimlerde (1930), sonra genel seçimlerde (1934) seçme ve seçilme hakkı tanındı. Ceza ve borçlar hukukunda \\\n",
    " seküler yasalar yürürlüğe konuldu. Sanayi Teşvik Kanunu kabul edildi. Toprak Reformu için çabalandı.[3] Arap harfleri temelli Osmanlı alfabesinin yerine \\\n",
    "  Latin harfleri temelli yeni Türk alfabesi kabul edildi. Halkı okuryazar kılmak için eğitim seferberliği başlatıldı. Üniversite Reformu gerçekleştirildi. \\\n",
    "  Birinci Beş Yıllık Sanayi Planı yürürlüğe konuldu. Sınıf ve statü farkı gözeten lâkap ve unvanlar kaldırıldı ve soyadları yürürlüğe konuldu. \\\n",
    "  Homojen ve birleşmiş bir ulus yaratılması için Türkleştirme politikası yürütüldü.[4][5][6] Türk olmayan azınlıklar kamuoyunda Türkçe konuşmaya zorlandı,[7] \\\n",
    "  Türkçe olmayan toponomiler ve azınlıkların soyadları Türkçeye çevrildi.[8][9]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 50.53it/s]\n",
      "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 5133.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.9999153630840389, 'start': 168, 'end': 179, 'answer': 'Yabancılara'}\n"
     ]
    }
   ],
   "source": [
    "print(nlp(question=\"Kimlere ekonomik imtiyaz kaldırıldı?\", context=ataturk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 76.76it/s]\n",
      "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 5405.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 1.3106855607656159e-09, 'start': 0, 'end': 8, 'answer': 'Atatürk'}\n"
     ]
    }
   ],
   "source": [
    "print(nlp(question=\"tüm bu devrimleri kim yaptı?\", context=ataturk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 69.47it/s]\n",
      "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 4364.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 9.457521791650177e-13, 'start': 1434, 'end': 1484, 'answer': 'Birinci Beş Yıllık Sanayi Planı yürürlüğe konuldu.'}\n"
     ]
    }
   ],
   "source": [
    "# Ask your self ! type your question\n",
    "print(nlp(question=\"...?\", context=ataturk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Text Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...will be soon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5- Text/Document Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this study we fine-tune 7 classes Turkish news dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following Turkish benchmark dataset is used for fine-tuning\n",
    "\n",
    "https://www.kaggle.com/savasy/ttc4900\n",
    "\n",
    " * 'LABEL_0': 'dunya \n",
    " * 'LABEL_1': 'ekonomi '\n",
    " * 'LABEL_2': 'kultur '\n",
    " * 'LABEL_3': 'saglik '\n",
    " * 'LABEL_4': 'siyaset '\n",
    " * 'LABEL_5': 'spor '\n",
    " * 'LABEL_6': 'teknoloji'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for BertForSequenceClassification:\n\tsize mismatch for classifier.weight: copying a param with shape torch.Size([7, 768]) from checkpoint, the shape in current model is torch.Size([2, 768]).\n\tsize mismatch for classifier.bias: copying a param with shape torch.Size([7]) from checkpoint, the shape in current model is torch.Size([2]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-4d983b1d6600>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# load models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"savasy/bert-turkish-text-classification\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"savasy/bert-turkish-text-classification\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/transformers/modeling_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    833\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mconfig_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_class\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m         raise ValueError(\n\u001b[1;32m    837\u001b[0m             \u001b[0;34m\"Unrecognized configuration class {} for this kind of AutoModel: {}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    611\u001b[0m                 raise RuntimeError(\n\u001b[1;32m    612\u001b[0m                     \"Error(s) in loading state_dict for {}:\\n\\t{}\".format(\n\u001b[0;32m--> 613\u001b[0;31m                         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\\t\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m                     )\n\u001b[1;32m    615\u001b[0m                 )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for BertForSequenceClassification:\n\tsize mismatch for classifier.weight: copying a param with shape torch.Size([7, 768]) from checkpoint, the shape in current model is torch.Size([2, 768]).\n\tsize mismatch for classifier.bias: copying a param with shape torch.Size([7]) from checkpoint, the shape in current model is torch.Size([2])."
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "from transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# load models\n",
    "tokenizer= AutoTokenizer.from_pretrained(\"savasy/bert-turkish-text-classification\")\n",
    "model= AutoModelForSequenceClassification.from_pretrained(\"savasy/bert-turkish-text-classification\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make pipeline\n",
    "nlp=pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# apply model\n",
    "res=nlp(\"bla bla\")\n",
    "res\n",
    "# [{'label': 'LABEL_2', 'score': 0.4753005802631378}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_to_label={\n",
    " 'LABEL_0': 'dunya ',\n",
    " 'LABEL_1': 'ekonomi ',\n",
    " 'LABEL_2': 'kultur ',\n",
    " 'LABEL_3': 'saglik ',\n",
    " 'LABEL_4': 'siyaset ',\n",
    " 'LABEL_5': 'spor ',\n",
    " 'LABEL_6': 'teknoloji '}\n",
    "# > 'kultur '\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_to_label[nlp(\"bla bla\")[0]['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"Bugün 19 Mayıs Atatürk'ü Anma, Gençlik ve Spor Bayramı. Mustafa Kemal Atatürk, 19 Mayıs 1919'da Bandırma Vapuru ile Samsun'a çıkmış ve İtilaf Devletleri'nin işgaline karşı Kurtuluş Savaşı'nı başlatmıştı. Siyaset Bilimci Prof. Dr. Ahmet Demirel, Mustafa Kemal'in askeri başarılarıyla tanınan bir Osmanlı paşasıyken tüm yurt çapında saygı duyulan siyasi bir lidere dönüşmesinin ilk adımı olan 19 Mayıs 1919'un öncesi ve sonrasında neler yaşandığını BBC Türkçe'ye anlattı.\"\n",
    "code_to_label[nlp(text)[0]['label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the details of traininig models please check\n",
    "\n",
    "* https://github.com/savasy/TurkishTextClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
